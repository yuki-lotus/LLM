{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QHOrGQAVkblE",
        "outputId": "3fae6569-9202-4126-fa63-264d63e3ef7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transformer為Huggingface的套件，需要Huggingface的token授權\n",
        "- 請至huggingface網站註冊並申請token，並把token加入colab中，名為<font color=red>HF_TOKEN</font>的環境變數\n",
        "- 可參考筆記[Huggingface與Transformer套件](https://hackmd.io/@shhuangmust/HyHNqjqfJg#/)\n",
        "- 從列印出來的模型參數中，可以看到Bert的embedding token數量有30522個(類似字典裏面的單字數量)，每個token有768維的隱向量空間(Latent vector space)\n"
      ],
      "metadata": {
        "id": "s_cNCyfYCqyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "model=AutoModel.from_pretrained(\"bert-base-uncased\");\n",
        "print(model)"
      ],
      "metadata": {
        "id": "K_kwVtOckuWO",
        "outputId": "76be398b-14e3-43b8-d48e-e083d2d5cd26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793,
          "referenced_widgets": [
            "eb6cb7d3699b493691bf23ce066a2df0",
            "0cc33346b1c247e5b909bd64e3364794",
            "a55d043ae06446d7a59ba7c0a955be21",
            "b02fed781d3746289a21f2c3b709013c",
            "ff2acf3c59384896856a9d1742bdb2bb",
            "5fc941757e2549c0843741f575068b01",
            "ae659502cdc747f482cc63999774e03c",
            "32431b7d3c92493eaf68e590a1d4278f",
            "6aa864d489fe4f3f9331b2ff6b8c7632",
            "7999daf06f2c433b90846a99998b1fa8",
            "4428c7d036c34fec83fb3729aecf5653",
            "934957005bdc41cd9ea3f1046d986b07",
            "d3f7cb6588b949bda3574029d1388e81",
            "bc2ef46373f1417990ed161a80d5a857",
            "0ed69f0850ed44de8cb011f7f9b1414d",
            "33e172b342264ccc82d58beb76932557",
            "118506e1928f45298202814e6316014f",
            "521c5756f45a4271b3f1fd6887dc0dfc",
            "ac81dfe18e8c4f21b073bdb1551cc221",
            "47c93c6958d1415da8ff69a64a79a83c",
            "1174742f535c4ac0878890cc91b46e33",
            "9b3944e4bd4c47b7ba08550c8c6a229c"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb6cb7d3699b493691bf23ce066a2df0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "934957005bdc41cd9ea3f1046d986b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert的參數總量為109,482,240，約一億個參數"
      ],
      "metadata": {
        "id": "UqwkzYrUFFEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.num_parameters())"
      ],
      "metadata": {
        "id": "Je0PkkY26tuF",
        "outputId": "95e94556-c972-4435-d584-57286a6782dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109482240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "QShJoYESlWh0",
        "outputId": "570446e6-8245-4410-d9ae-e33d3bb547c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "8fcf0839773844fabf0ac37eea7f85c5",
            "9fb3d2330dac4fad920e260948846b02",
            "7bfb98f67f674193933281694689ce81",
            "a81ac19218ca457391ca8033e5f3e61b",
            "fe5c4bc92ba847de9975598d1533b828",
            "b318dd9304a845d2982a7175110e8f26",
            "cb5c1c08addd402a9d90251456945442",
            "f389a2ebad394e1fa1136027ccc660d3",
            "303c58f4e37b459c89b31e54f451de2b",
            "c77ee2a97fc7446d873e7e16c6a8dc7e",
            "e26e350636604d1c9756e4c3e6ff0327",
            "34afe79a615c42a191296518583e7e17",
            "0a7b7bf43272455db97f7fcd15850ee3",
            "053c665902a844e3baa47defbc1e4abb",
            "a8e0c24e2cf7475db25424d7f8aff8d6",
            "2e3794818f6443bb879a570962712d06",
            "c7754f9862c048ac976b7b64e0c43944",
            "225123be27ac448f94761c84e2384aee",
            "69d0bab7f2574aacbd205892b9ca0948",
            "25a1eab344714eb7b3b80ff8bd059561",
            "3f0d4e6443b04b458845a4e26ecafce7",
            "fa5ae0a5d55644e88b212b41943bb168",
            "2b73fb22ffd24915aacc3f50576202dd",
            "9a6cccaa22bf402da2580cfefd40973c",
            "681524eab4354a6b926bb9a6151645a4",
            "5e6c0a77bfc143039635902fa43f679c",
            "2d917795c98a4985a2e130565bcc8c77",
            "a872c1ff1e874cb78cf249efde2eb072",
            "8f5665fe34f74e438f13891e19db698a",
            "ba5fcefad0dc4ab2bd3d43ba9b6c9f22",
            "32ae9a23e6294c9491ef7d9eb167d25f",
            "11d52e27e35a4b37b7861152357b00ae",
            "ac2c87492a2444daa75cb64a3e5645cc"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fcf0839773844fabf0ac37eea7f85c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34afe79a615c42a191296518583e7e17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b73fb22ffd24915aacc3f50576202dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ]
    }
  ]
}
